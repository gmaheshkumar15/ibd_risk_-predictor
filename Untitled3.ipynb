{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c682a841-d527-4534-898c-41b46d745c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data loaded successfully!\n",
      "data.shape: (1129, 23)\n",
      "Training samples: 903\n",
      "Test samples: 226\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Step 1: Data Loading and Preprocessing\n",
    "# ===============================\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1Ô∏è‚É£ Load data\n",
    "data = pd.read_excel(\"Merged.xlsx\")\n",
    "\n",
    "# 2Ô∏è‚É£ Separate features and target\n",
    "X = data.drop(columns=[\"Label\"])\n",
    "y = data[\"Label\"]\n",
    "\n",
    "# 3Ô∏è‚É£ Train-test split (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "\n",
    "print(\"‚úÖ Data loaded successfully!\")\n",
    "print(\"data.shape:\",data.shape)\n",
    "print(\"Training samples:\", X_train.shape[0])\n",
    "print(\"Test samples:\", X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab3fa45e-7cb2-4329-9072-378d097a842b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Model Performance:\n",
      "Logistic Regression   Accuracy: 0.956  AUC: 0.991\n",
      "Random Forest         Accuracy: 0.996  AUC: 0.999\n",
      "XGBoost               Accuracy: 0.996  AUC: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:24:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Step 2: Model Training\n",
    "# ===============================\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import joblib\n",
    "\n",
    "# Logistic Regression\n",
    "log_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_model.fit(X_train, y_train)\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200, random_state=42, max_depth=6\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=200, learning_rate=0.05, max_depth=4, random_state=42, use_label_encoder=False, eval_metric=\"logloss\"\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# ===============================\n",
    "# Step 3: Evaluate Models\n",
    "# ===============================\n",
    "models = {\n",
    "    \"Logistic Regression\": log_model,\n",
    "    \"Random Forest\": rf_model,\n",
    "    \"XGBoost\": xgb_model\n",
    "}\n",
    "\n",
    "print(\"\\nüìä Model Performance:\")\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    print(f\"{name:20s}  Accuracy: {acc:.3f}  AUC: {auc:.3f}\")\n",
    "\n",
    "# ============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5322d90b-b5e2-4130-85ab-65f4a2f54d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:24:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Model Performance (No Scaling):\n",
      "Logistic Regression   Accuracy: 0.956  AUC: 0.991\n",
      "Random Forest         Accuracy: 0.996  AUC: 0.999\n",
      "XGBoost               Accuracy: 0.996  AUC: 1.000\n",
      "\n",
      "üíæ Models saved successfully (no scaling used)!\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# IBD Prediction Model Training (No Scaling)\n",
    "# ======================================\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import joblib\n",
    "\n",
    "# -------------------------\n",
    "# Load and split data\n",
    "# -------------------------\n",
    "data = pd.read_excel(\"Merged.xlsx\")\n",
    "\n",
    "X = data.drop(columns=[\"Label\"])\n",
    "y = data[\"Label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Train models\n",
    "# -------------------------\n",
    "log_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_model.fit(X_train, y_train)\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200, random_state=42, max_depth=6\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=200, learning_rate=0.05, max_depth=4,\n",
    "    random_state=42, use_label_encoder=False, eval_metric=\"logloss\"\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------\n",
    "# Evaluate models\n",
    "# -------------------------\n",
    "models = {\n",
    "    \"Logistic Regression\": log_model,\n",
    "    \"Random Forest\": rf_model,\n",
    "    \"XGBoost\": xgb_model\n",
    "}\n",
    "\n",
    "print(\"\\nüìä Model Performance (No Scaling):\")\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    print(f\"{name:20s}  Accuracy: {acc:.3f}  AUC: {auc:.3f}\")\n",
    "\n",
    "# -------------------------\n",
    "# Save models\n",
    "# -------------------------\n",
    "joblib.dump(log_model, \"logistic_model.pkl\")\n",
    "joblib.dump(rf_model, \"rf_model.pkl\")\n",
    "joblib.dump(xgb_model, \"xgb_model.pkl\")\n",
    "\n",
    "print(\"\\nüíæ Models saved successfully (no scaling used)!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4499ba50-d079-4b88-8973-f6654c8b0072",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:31:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Model Performance:\n",
      "Logistic Regression  Accuracy: 0.956  AUC: 0.991\n",
      "Random Forest        Accuracy: 0.996  AUC: 0.999\n",
      "XGBoost              Accuracy: 0.996  AUC: 1.000\n",
      "\n",
      "üíæ Models and SHAP values saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import joblib\n",
    "import shap\n",
    "\n",
    "# --------------------------\n",
    "# Load Dataset\n",
    "# --------------------------\n",
    "data = pd.read_excel(\"Merged.xlsx\")\n",
    "X = data.drop(columns=[\"Label\"])\n",
    "y = data[\"Label\"]\n",
    "\n",
    "# --------------------------\n",
    "# Train-Test Split\n",
    "# --------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# --------------------------\n",
    "# Train Models\n",
    "# --------------------------\n",
    "log_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_model.fit(X_train, y_train)\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=200, max_depth=6, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=200, learning_rate=0.05, max_depth=4,\n",
    "    random_state=42, use_label_encoder=False, eval_metric=\"logloss\"\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# --------------------------\n",
    "# Evaluate Models\n",
    "# --------------------------\n",
    "models = {\n",
    "    \"Logistic Regression\": log_model,\n",
    "    \"Random Forest\": rf_model,\n",
    "    \"XGBoost\": xgb_model\n",
    "}\n",
    "\n",
    "print(\"\\nüìä Model Performance:\")\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    print(f\"{name:20s} Accuracy: {acc:.3f}  AUC: {auc:.3f}\")\n",
    "\n",
    "# --------------------------\n",
    "# Compute SHAP values (Random Forest)\n",
    "# --------------------------\n",
    "explainer = shap.TreeExplainer(rf_model)\n",
    "shap_values = explainer.shap_values(X_train)  # list of arrays for binary classification\n",
    "\n",
    "# Save models and SHAP values\n",
    "joblib.dump(log_model, \"logistic_model.pkl\")\n",
    "joblib.dump(rf_model, \"rf_model.pkl\")\n",
    "joblib.dump(xgb_model, \"xgb_model.pkl\")\n",
    "joblib.dump(shap_values, \"rf_shap_values.pkl\")\n",
    "joblib.dump(X_train, \"X_train.pkl\")\n",
    "\n",
    "print(\"\\nüíæ Models and SHAP values saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee85273b-7528-4401-bb1f-8c995043810d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Asus\\\\MTP PROJECT'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7464d128-1168-4cf2-a905-a6240698d408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [03:50:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Models and feature names saved in 'C:\\Users\\Asus\\MTP PROJECT'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "\n",
    "# -------------------------------\n",
    "# Load dataset\n",
    "# -------------------------------\n",
    "data = pd.read_excel(\"Merged.xlsx\")\n",
    "X = data.drop(columns=[\"Label\"])\n",
    "y = data[\"Label\"]\n",
    "\n",
    "# -------------------------------\n",
    "# Train-test split\n",
    "# -------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Train models\n",
    "# -------------------------------\n",
    "log_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_model.fit(X_train, y_train)\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=200, max_depth=6, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=4,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------------\n",
    "# Save models & feature names\n",
    "# -------------------------------\n",
    "folder_path = r\"C:\\Users\\Asus\\MTP PROJECT\"\n",
    "\n",
    "joblib.dump(log_model, f\"{folder_path}\\\\logistic_model.pkl\")\n",
    "joblib.dump(rf_model, f\"{folder_path}\\\\rf_model.pkl\")\n",
    "joblib.dump(xgb_model, f\"{folder_path}\\\\xgb_model.pkl\")\n",
    "\n",
    "# Save exact feature names (important for SHAP)\n",
    "feature_names = list(X.columns)\n",
    "joblib.dump(feature_names, f\"{folder_path}\\\\rf_features.pkl\")\n",
    "\n",
    "print(f\"‚úÖ Models and feature names saved in '{folder_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2041f4-a2b5-4e44-8845-8df76db97fec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
